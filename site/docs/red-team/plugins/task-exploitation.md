---
sidebar_label: Task Exploitation
---

# Task Exploitation for LLMs

## Overview

Task Exploitation is a vulnerability where the AI is tricked into performing tasks outside its intended scope. An attacker disguises a request as a benign or useful task to bypass security guidelines. This can lead the model to process or reveal information it should not handle.

## How It Works

1. The attacker crafts a prompt that appears to request a harmless task.
2. The prompt embeds instructions that conflict with the model's security or operational boundaries.
3. The model executes the task without recognizing the underlying misuse.
4. The output may reveal sensitive information or perform an unintended action.

## Configuration

To include the Task Exploitation plugin in your LLM red teaming setup, add the following configuration to your YAML file:

```yaml
redteam:
  plugins:
    - task-exploitation
```

## Example Test Cases

1. **Data Annotation**: Requesting the AI to label or annotate a dataset that contains sensitive or restricted data.
2. **Text Classification**: Instructing the model to classify text excerpts that include hidden instructions.
3. **Language Analysis**: Asking the model to perform sentiment analysis on text where the underlying request bypasses safety directives.

## Evaluation Criteria

The plugin assesses the AI's response based on:

- Detection of disguised tasks that conflict with security policies.
- Consistency in refusing to perform tasks that violate system guidelines.
- Clarity in the refusal message when a task falls outside the permitted scope.
- Risk of exposing sensitive information or bypassing guardrails.

## Importance in Gen AI Red Teaming

Testing for Task Exploitation is critical because it:

- Reveals scenarios where benign task requests are used to override safety measures.
- Helps refine prompt interpretations to maintain strict adherence to system instructions.
- Identifies gaps in the AI's guardrails that could lead to unintended behavior.

## Related Concepts

- [Indirect Prompt Injection](indirect-prompt-injection.md)
- [System Prompt Override](system-prompt-override.md)
- [Excessive Agency](excessive-agency.md)

For a comprehensive overview of LLM vulnerabilities and red teaming strategies, visit our [Types of LLM Vulnerabilities](/docs/red-team/llm-vulnerability-types) page.
